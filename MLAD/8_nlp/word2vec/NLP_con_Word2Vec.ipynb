{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmudJGmTNFML"
   },
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YqG5NoTJbuV8"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17305,
     "status": "ok",
     "timestamp": 1729616078367,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "OObCHIjPbt9z",
    "outputId": "987e3629-9e6a-46ed-bced-e46305a16aa0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1TFr2_ttTpF9"
   },
   "source": [
    "## Un modelo Word2Vec pre-entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(gensim.downloader.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13113,
     "status": "ok",
     "timestamp": 1729616376952,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "a7oiP209Jvs1"
   },
   "outputs": [],
   "source": [
    "# Cargamos el modelo pre-entrenado\n",
    "w2v = gensim.downloader.load('glove-wiki-gigaword-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 324,
     "status": "ok",
     "timestamp": 1729616387431,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "CzIE01aeUC1t",
    "outputId": "8e2be22c-80bd-4c50-c02b-d3c0a6c4c30b"
   },
   "outputs": [],
   "source": [
    "# Primeros 10 tokens del vocabulario\n",
    "w2v.index_to_key[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1729616390666,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "cjLhwB_4W4BG",
    "outputId": "f69ba506-03b8-4a35-a0b5-aee1c0b6b00c"
   },
   "outputs": [],
   "source": [
    "# Total de tokens en el vocabulario\n",
    "len(w2v.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 306,
     "status": "ok",
     "timestamp": 1729616392629,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "xENiOqfMXUDY",
    "outputId": "e4b9053e-a9ef-4580-9c0c-08b9ef881e98"
   },
   "outputs": [],
   "source": [
    "# Dimensión del embedding\n",
    "w2v['play'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1729616394295,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "G--mY7B3Ur7E",
    "outputId": "eda56b02-2101-49da-a805-e5deade3ca2d"
   },
   "outputs": [],
   "source": [
    "# Devuelve lista de las 5 palabras más similares a 'king' y su similitud.\n",
    "similar_words = w2v.most_similar('king', topn=5)\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 300,
     "status": "ok",
     "timestamp": 1729616407063,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "DoSZWag1VNHM",
    "outputId": "72027282-d71a-4b31-85e8-fe8956e24bcf"
   },
   "outputs": [],
   "source": [
    "# Esto debería devolver algo cercano a 'queen'.\n",
    "result = w2v.most_similar(positive=['king', 'woman'], negative=['man'], topn=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1729616416173,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "1BLCNAa3V4JJ",
    "outputId": "0d58cbfb-b269-4280-c67a-6c5aa96f27df"
   },
   "outputs": [],
   "source": [
    "# Esto devuelve un valor entre -1 y 1, donde 1 indica que son muy similares.\n",
    "similarity = w2v.similarity('king', 'queen')\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1729616417071,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "Z950Y6JgWDil",
    "outputId": "ec986b1b-9601-4ef1-a5d5-eb06f5d5a203"
   },
   "outputs": [],
   "source": [
    "# Esto debería devolver 'car', ya que no es una comida.\n",
    "odd_one_out = w2v.doesnt_match(['breakfast', 'lunch', 'dinner', 'car'])\n",
    "print(odd_one_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "executionInfo": {
     "elapsed": 989,
     "status": "ok",
     "timestamp": 1729616423105,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "DKJAYQOlWQfB",
    "outputId": "e6cfc66e-90d3-47cd-960d-a2d1def3816b"
   },
   "outputs": [],
   "source": [
    "# Selecciona las palabras que quieres visualizar\n",
    "words = ['king', 'queen', 'man', 'woman']\n",
    "\n",
    "# Extrae los vectores de esas palabras\n",
    "word_vectors = [w2v[word] for word in words]\n",
    "\n",
    "# Aplica PCA para reducir la dimensionalidad a 2D\n",
    "pca = PCA(n_components=2)\n",
    "word_vecs_2d = pca.fit_transform(word_vectors)\n",
    "\n",
    "# Graficar los resultados\n",
    "plt.figure(figsize=(4, 3))\n",
    "for i, word in enumerate(words):\n",
    "    plt.scatter(word_vecs_2d[i][0], word_vecs_2d[i][1])\n",
    "    plt.annotate(word, (word_vecs_2d[i][0], word_vecs_2d[i][1]))\n",
    "\n",
    "plt.title(\"Visualización de Word2Vec\")\n",
    "plt.xlabel(\"Componente 1\")\n",
    "plt.ylabel(\"Componente 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7wfaxkscEYL"
   },
   "source": [
    "## Embedding de documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_i90a4XdTZx"
   },
   "source": [
    "Vamos a usar el dataset de IMDB para clasificación de reseñas de películas, el objetivo del mismo es detectar si una reseña tiene sentimiento **positivo** o **negativo**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3065,
     "status": "ok",
     "timestamp": 1729616483992,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "IIialWv2dLjE"
   },
   "outputs": [],
   "source": [
    "imdb_data = pd.read_csv(\"./IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 1060,
     "status": "ok",
     "timestamp": 1729616487879,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "n5sOz-yvdZA1",
    "outputId": "889b7c21-64c9-449d-8c80-19dc481f8d73"
   },
   "outputs": [],
   "source": [
    "imdb_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "executionInfo": {
     "elapsed": 323,
     "status": "ok",
     "timestamp": 1729616494645,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "vyEp-C4Idli0",
    "outputId": "e4b64d49-6212-4c87-ead0-2306e6c39960"
   },
   "outputs": [],
   "source": [
    "imdb_data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1729616497728,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "vQYe0Edtdt0q"
   },
   "outputs": [],
   "source": [
    "# Convert positive and negative into binary classes (1-0)\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "sentiment_data = lb.fit_transform(imdb_data[\"sentiment\"])\n",
    "imdb_data['sentiment'] = sentiment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 951,
     "status": "ok",
     "timestamp": 1729616506156,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "3PoK4VqVd29y",
    "outputId": "31a43af9-182f-4ee1-8180-3864957e06b8"
   },
   "outputs": [],
   "source": [
    "imdb_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lkr7Vz950IeY"
   },
   "source": [
    "Primero haremos:\n",
    "1.   Eliminar tags html (vamos a utilizar BeautifulSoup para esto)\n",
    "2.   Eliminar texto entre parentesis rectos (Usando la siguiente expresion regular: ```\\[[^]]*\\]``` )\n",
    "3. Eliminar caracteres especiales, usando una regex quitar todos los caracteres que no son ni letras ni números (```[^a-zA-z0-9\\s] ``` )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1729616510509,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "SIiaBeGOwIOQ"
   },
   "outputs": [],
   "source": [
    "def strip_html(text):\n",
    "  soup = BeautifulSoup(text, 'html.parser')\n",
    "  return soup.get_text()\n",
    "\n",
    "def remove_between_square_brackets(text):\n",
    "  out = re.sub('\\[[^]]*\\]','',text)\n",
    "  return out\n",
    "\n",
    "def remove_special_characters(text):\n",
    "  out = re.sub('[^a-zA-Z0-9\\s]','',text)\n",
    "  return out\n",
    "\n",
    "def low_level_preproc(text):\n",
    "  return remove_special_characters(remove_between_square_brackets(strip_html(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14468,
     "status": "ok",
     "timestamp": 1729616528443,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "-WY4ZETXMAEI",
    "outputId": "d71c9349-f115-4929-b88b-a5813565ee4a"
   },
   "outputs": [],
   "source": [
    "imdb_data['review'] = imdb_data['review'].apply(low_level_preproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGJUuc0O16iv"
   },
   "source": [
    "Una vez tenemos el texto limpio y trabajable volvemos a hacer otro pasaje de preprocesamiento de más alto nivel, ahora vamos a querer:\n",
    "\n",
    "1.   Transformar todo el texto a minúscula\n",
    "2.   Quitar stop words (usando nltk)\n",
    "3.   Lemmatizar usando nltk WordNetLemmatizer\n",
    "\n",
    "Para todo esto vamos a necesitar trabajar con **tokens** palabras individuales, en este caso vamos a separar por **whitespace**, pero se podrían usar mejores estrategias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1729616668635,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "KeKNTxvzwISR"
   },
   "outputs": [],
   "source": [
    "all_stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "def remove_stop_words(full_text_line):\n",
    "  tokens = full_text_line.split(\" \")\n",
    "  result = [token for token in tokens if token not in all_stopwords]\n",
    "  return result\n",
    "\n",
    "def lemmatize(tokens):\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  result = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "  return result\n",
    "\n",
    "def high_level_preproc(text):\n",
    "  result = remove_stop_words(text)\n",
    "  result = lemmatize(result)\n",
    "  return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 32897,
     "status": "ok",
     "timestamp": 1729616704369,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "8_vndgn4MAEP"
   },
   "outputs": [],
   "source": [
    "imdb_data['review'] = imdb_data['review'].str.lower()\n",
    "imdb_data['review'] = imdb_data['review'].apply(high_level_preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1729616704370,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "9k3wz_XUql1d",
    "outputId": "8adaaee8-757f-4e23-c29c-082f718895af"
   },
   "outputs": [],
   "source": [
    "imdb_data['review'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1729616719726,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "M5C-sopMWkIt"
   },
   "outputs": [],
   "source": [
    "mean_vector = np.mean(w2v.vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 549,
     "status": "ok",
     "timestamp": 1729616722269,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "wDrlSMTCf7az"
   },
   "outputs": [],
   "source": [
    "def get_sentence_embedding(text):\n",
    "  tokens = text.split(\" \")\n",
    "  embeddings = [w2v[token] if token in w2v else mean_vector for token in tokens]\n",
    "  return np.mean(np.array(embeddings), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22453,
     "status": "ok",
     "timestamp": 1729616746351,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "9qNyNIldf4_B"
   },
   "outputs": [],
   "source": [
    "review_vectors = [get_sentence_embedding(sent) for sent in imdb_data.review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "executionInfo": {
     "elapsed": 3956,
     "status": "ok",
     "timestamp": 1729616790172,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "uOBmyKy7gZWp",
    "outputId": "495b7515-570c-4bb2-b8f3-0c07211c7226"
   },
   "outputs": [],
   "source": [
    "# Aplica PCA para reducir la dimensionalidad a 2D\n",
    "review_vectors = np.array(review_vectors)\n",
    "pca = PCA(n_components=2)\n",
    "review_vectors_2d = pca.fit_transform(review_vectors)\n",
    "\n",
    "# Graficar los resultados\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Definir los colores para cada clase 0 y 1\n",
    "colors = ['tab:red' if sentiment == 0 else 'tab:blue' for sentiment in imdb_data['sentiment']]\n",
    "\n",
    "# Hacer el scatter plot\n",
    "scatter = plt.scatter(review_vectors_2d[:, 0], review_vectors_2d[:, 1], c=colors)\n",
    "\n",
    "# Añadir el título y etiquetas de ejes\n",
    "plt.title(\"Visualización de Word2Vec con PCA\")\n",
    "plt.xlabel(\"Componente 1\")\n",
    "plt.ylabel(\"Componente 2\")\n",
    "\n",
    "# Añadir leyenda manualmente para 0 y 1\n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', markerfacecolor='tab:red', markersize=10, label='Sentimiento 0'),\n",
    "                   Line2D([0], [0], marker='o', color='w', markerfacecolor='tab:blue', markersize=10, label='Sentimiento 1')]\n",
    "plt.legend(handles=legend_elements)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EhMotVweNRWF"
   },
   "source": [
    "### Crear dataframe\n",
    "\n",
    "Si hubieran más columnas en el dataset original, lo concatenamos luego de crear el dataframe con los embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "executionInfo": {
     "elapsed": 310,
     "status": "ok",
     "timestamp": 1729617177639,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "_-clm9HoN4FQ",
    "outputId": "86106688-62bf-4e59-eba4-cd14e7aa482f"
   },
   "outputs": [],
   "source": [
    "embedding_df = pd.DataFrame(review_vectors)\n",
    "embedding_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwvZfIlJNOHr"
   },
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1729617369824,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "F1lpT9wfNMqj"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "random_state = 17\n",
    "\n",
    "X, y = embedding_df, imdb_data[\"sentiment\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=(1.0/3),\n",
    "    random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5iXoQBR_NKWi"
   },
   "source": [
    "## Modelo de Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "executionInfo": {
     "elapsed": 1186,
     "status": "ok",
     "timestamp": 1729617446354,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "LOyJZ9TMOsQp",
    "outputId": "bb670e1f-931d-4e77-ba9f-102ff20ccf05"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1729617447812,
     "user": {
      "displayName": "Alejo Garat",
      "userId": "02818908258948244793"
     },
     "user_tz": 180
    },
    "id": "zw9TIvErOwDr",
    "outputId": "9acc38c4-1442-4f4b-9505-d7fff89a0914"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_train_pred = log_reg.predict(X_train)\n",
    "print(f\"Train accuracy: {accuracy_score(y_train, y_train_pred)}\")\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, y_pred)}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
